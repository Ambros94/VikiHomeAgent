% !TEX encoding = UTF-8 Unicode
\documentclass[twoside]{supsistudent} 
\usepackage{booktabs}
\usepackage{float}
\usepackage{notes}
\usepackage[normalem]{ulem}
\usepackage{url}
\restylefloat{table}
% per settare noindent
\setlength{\parindent}{0pt}


% Crea un capitolo senza numerazione che pero` appare nell'indice %
\newcommand{\problemchapter}[1]{%
  \chapter*{#1}%
  \addcontentsline{toc}{chapter}{#1}%
\markboth{#1}{#1}
}

% Numerazione delle appendici secondo norma
\addto\appendix{
\renewcommand{\thesection}{\Alph{chapter}.\arabic{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}}

\setcounter{secnumdepth}{5} 	%per avere più livelli nei titoli
\setcounter{tocdepth}{5}		%per avere più livelli nell'indice


\titolo{Viki: Smart Home Natural Language interface }
\studente{Luca Ambrosini}
\relatore{Nicola Rizzo}
\correlatore{Alan Ferrari}
\committente{-}
\corso{-}
\modulo{M00002 Progetto di diploma}
\anno{2015/16}

\begin{document}

\pagenumbering{alph}
\maketitle
\onehalfspacing
\frontmatter

%	Indici vari

\pagenumbering{roman}
%\tableofcontents
%\listoffigures					
%\listoftables					

\newpage
\mainmatter
\pagenumbering{arabic}
\setcounter{page}{1}

%	Inizio Documento
\chapter{Introduzione}

Disegnare una macchina in grado di comportarsi come un umano, in particolare di parlare e interpretare il linguaggio\color{red}, \color{black}  è uno degli obbiettivi dell'ingegneria sin da metà del 20esimo secolo. Le interfacce in linguaggio naturale  sono considerate come il punto di arrivo dell'interazione uomo macchina.
Lo sviluppo in questo campo è stato molto intenso negli ultimi anni ciò ha permesso la realizzazione di agenti intelligenti, che simulino una conversazione con la persona e che riescano a compiere azioni più complesse di semplici comandi con frasi standardizzate.

\section{La voce come mezzo di comunicazione}

\section{Cenni storici}

Il primo esempio nella storia di dispositivo ad interazione vocale è da collocare nell'estate del 1952, presso i laboratori Bell.
Quell'anno vennero eseguiti i primi test di "Audrei" (Automatic Digit Recognizer), un dispositivo in grado di comporre un numero di telefono dettato ad un microfono.

Nel 1962 IMB presentò "Shoebox", una macchina in grado di comprendere 16 diverse parole pronunciate in inglese. Questa macchina era destinata ad essere una calcolatrice vocale.

Lo sviluppo di sistemi in grado di comprendere il linguaggio naturale è poi proseguito nel tempo, passando dalla comprensione di pochi suoni alla comprensione continua del linguaggio naturale; le tecniche si sono evolute passando da metodi statistici fino ad approcci basati sul deep learning. Esso è una branchia del machine learning, che simula delle reti neurali multi strato che riescono ad apprendere funzioni complesse. \cite{deeplearninggeneral}

Grossi miglioramenti in questo campo sono pervenuti nell'ultimo secolo, soprattuto grazie all'incremento delle capacità computazionali. Questo ha permesso la realizzazione di agenti intelligenti sempre più complessi.

\section{Evoluzione degli agenti}

I primi dispositivi ad interazione vocali sono gli "Interactive Voice Response", cioè gli agenti dei call center, che descrivono attraverso la voce i comandi e ricevono input attraverso i numeri digitati sul telefono. Il numero di input era quindi molto ridotto e la struttura della conversazione era fissa.

Successivamente i lettori automatici e i dispositivi ad interazione vocale sono stati integrati nei sistemi operativi. La loro funzione principale consisteva nell'aiutare le persone con delle disabilità. Era comunque necessario un microfono, quindi una prossimità al computer. Inoltre la voce aveva una funzione di sostituzione delle capacità visive o motorie non erano previste funzionalità dedicate che permettessero una maggior produttività.

Con l'ultima generazione di smartphone, che sono dotati di un microfono e che dispongono di una connessione a Internet, gli agenti intelligenti sono diventati parte della nostra vita quotidiana. Vista la limitata capacità di calcolo degli smartphone tutto il processamento dell'informazione viene eseguito attraverso cloud computing, che utilizza tecniche di deep learning.

L'ultima generazione di dispositivi ad interazione vocale è costituita da "Amazon Echo" e "Microsoft Kinect", essi sono in grado di ricevere input vocali in modo continuo, senza che l'utente debba avere un microfono addosso e senza che venga azionato un dispositivo. Questo ha portato l'interazione vocale  a un nuovo livello di usabilità e ha aperto nuove possibilità di utilizzo di questa tecnologia nell'ambito delle smart home.

\section{Il momento giusto}

Storicamente lo scetticismo a proposito delle interfacce in linguaggio naturale è sempre stato molto elevato: soprattuto per la loro scarsa produttività sono sempre state considerate un accessorio e non una tecnologia che potesse essere sfruttata.
Ora però tutte le tecnologie necessarie alla realizzazione di un agente intelligente che ci possa aiutare nella vita quotidiana sono pronte:
\begin{itemize}
  \item \textbf{Speech-To-Text}: Negli ultimi anni, soprattuto grazie alle tecniche di machine learning, questa tecnologia è arrivata ad alti livelli di accuratezza, superando in alcuni casi perfino le capacità di percezione dell'uomo. Sono ormai disponibili componenti che eseguono speech-to-text in tutte le lingue del mondo.\cite{sttmachinelearning}
   \item \textbf{Comprensione del testo}: L'analisi semantica, la vettorizzazione di parole e frasi, permettono una sempre maggior strutturazione del contenuto del testo, la quale consente una migliore comprensione da parte delle macchine.\cite{word2vec}
    \item \textbf{Connessione}: La capacità di calcolo richiesta per effettuare STT e comprendere un testo è molto elevata, per questo in genere si ricorre a un server remoto; l'incremento della larghezza di banda e la diminuzione dei tempi di latenza hanno reso possibile delle risposte in tempi adeguati.
     \item \textbf{Audio always on}: La tecnologia ha permesso la creazione di dispositivi che ascoltano in modo continuo e sono in grado di riconoscere delle keyword per la loro attivazione ("Ehi Siri"), le persone inoltre si sono abituate e hanno imparato ad accettare questa profonda invasione della privacy.
     \item \textbf{IOT}: Si stima che il mercato dell'IOT raggiunga una cifra d'affari di 1200 Miliardi di \$ entro il 2020 e l'home automation è uno dei settori nei quali un agente può raggiungere la sua massima utilità. 
\end{itemize}

\chapter{Caso d'uso}

L'utilità degli Agenti Intelligenti ad interazione vocale è spesso messa in dubbio, ma ci sono alcune occasioni nelle quali le loro capacità brillano, poiché forniscono un'esperienza d'uso diversa dalle interfacce basate su schermi o touch.
\begin{itemize}
	\item \textbf{Accessibilità}: Consentono un'esperienza d'uso soddisfacente a persone con disabilità motorie o visive, in quanto la procedura di descrizione delle operazione possibili e la successiva richiesta di un input non è più necessaria, gli agenti possono infatti eseguire comandi in risposta a frasi come "Manda un messaggio a Mario dicendo che arriverò tardi"
	\item \textbf{Eye-busy o Hand-busy}: In scenari quali la guida o attività svolte in cucina, in cui si hanno le mani impegnate e non si ha la possibilità di concentrare la propria attenzione su uno schermo, gli Agenti Intelligenti diventano particolarmente utili.
	\item \textbf{Automazione casalinga}: Supportare la creazione di comandi complessi a discrezione dell'utente, che permettano di compiere azioni in modo semplificato. Ad esempio "Buonanotte" potrebbe automaticamente abbassare tutte le tapparelle e spegnere tutte le luci.
\end{itemize}
In queste situazioni sarebbe quindi ideale avere un agente in grado di svolgere per noi la maggior parte delle operazioni che gli vengono indicate attraverso la voce, come se stessimo conversando con una persona alla quale chiediamo di svolgere il compito.

\chapter{Obbiettivo}

Il progetto è basato su "Viki", un Agente Intelligente\cite{agenteinteligente}, capace di controllare molti degli apparecchi presenti in un abitazione e di fornire informazioni, ad esempio riguardanti il meteo.
Esso è stato sviluppato presso l'Istituto Sistemi Informativi e Networking. 
Il primo obbiettivo del progetto di bachelor consiste nella comprensione dell'infrastruttura del sistema attuale; successivamente si  vuole migliorare l'interazione vocale con il sistema, cercando di renderla il meno rigida possibile. Inoltre si provvederà all'estensione delle API disponibili e si implementeranno strutture che miglioreranno l'intelligenza dell'agente attuale.

\section{Interfaccia in linguaggio naturale}
\subsection{Grammatiche fisse}
Il sistema attuale prevede l'interazione vocale, ma utilizza un sistema basato su delle grammatiche fisse. Questo implica quindi una struttura della frase definita a priori dal programmatore, che nel caso non sia rispettata, impedisce la comprensione del comando da parte dell'agente.
\subsection{Rimozione dei vincoli}
Il progetto aspira a creare un interfaccia libera da questi vincoli, che provi a comprendere il senso della frase in modo indipendente dai singoli vocaboli e dalla struttura utilizzata.
Grazie all'interfaccia libera l'utilizzatore può concentrarsi sull'azione da eseguire e meno su come esprimerla per far si che l'agente sia in grado di comprenderla. Una delle critiche che viene più spesso mossa alle interfacce in linguaggio naturale è la necessità dell'utilizzatore di compiere uno sforzo mentale per pensare come la macchina.
Grazie alla rimozione di questi vincoli l'utilizzatore dovrebbe trovare l'interazione con l'agente più simile a una conversazione tra persone, garantendo quindi una maggior soddisfazione.
Un'interfaccia di questo livello semplificherebbe l'utilizzo di una smart home al punto di renderla fruibile anche a persone che non si trovano normalmente a loro agio con la tecnologia.
\section{Incremento delle API}
\subsection{API attuali}
Le capacità del sistema sono strettamente collegate alla mole di informazioni alle quali esso ha acceso e ai dispositivi che è in grado di controllare. 
Al momento Viki può controllare :
\begin{itemize}
  \item Lampadine philips HUE (accensione, colorazione, intensità)
  \item Prese di corrente z-wave (accensione, lettura potenza istantanea)
\end{itemize}
e ha accesso alle seguenti informazioni:
\begin{itemize}
  \item Sensori di movimento, luminosità, umidità, temperatura
  \item Previsioni meteo (yahoo)
\end{itemize}
\subsection{API future}
Durante lo sviluppo del progetto di bachelor si vogliono incrementare le capacità del sistema, in particolare Viki dovrà essere in grado di controllare:
\begin{itemize}
  \item Tapparelle motorizzate
  \item Mediacenter
  \item Impostazione di sveglie
  \item Impostazione di promemoria
  \item Aggiunta eventi calendario
  \item Impostazioni timer
\end{itemize}
e avrà accesso a informazioni aggiuntive quali :
\begin{itemize}
  \item Palinsesto televisivo (RSI, Mediaset, Rai)
\end{itemize}

\section{If then else}
Sviluppo futuro

\chapter{Comunicazione engine - voice }
Il modulo di interazione vocale è realizzato come un componente esterno dal sistema di gestione dell'abitazione, cioè quello che si occupa di accedere alle informazioni e di azionare gli attuatori. E' stato quindi necessario definire un protocollo che informasse il sistema di controllo vocale di quali operazioni possono essere compiute e quali tipologie di informazioni sono disponibili.
\section{Struttura dell'informazione}
Per definizione l'insieme delle operazioni che il sistema di gestione è in grado di compiere abbiamo definito la seguente struttura:
\begin{itemize}
	\item \textbf{Universe}: l'insieme di tutti i domini.
	\item \textbf{Domain}: un oggetto o un dominio di informazione che il sistema rende disponibile, per essere azionata o interrogata (es. Lampada, Tapparella, Meteo, Palinsesto)
	\item \textbf{Operation}: sono definite nell'ambito di un dominio e rappresentano le operazioni che possono essere richieste (es accensione di una luce, richiesta delle previsioni metereologiche)
	\item \textbf{Parameters}: sono definiti nell'ambito di un operazioni e rappresentano i parametri che possono essere associati a un operazione (es. colore da impostare per la lampada, luogo per le previsioni metereologiche)
	\item \textbf{ParameterType}: i parametri precedentemente definiti devono essere di una tipologia specifica(es. Data, Luogo)
\end{itemize}
\subsection{Tipologie di parametri}
Il sistema supporta parametri tipizzati, che possono appartenere alle seguenti categorie:
\begin{itemize}
	\item LOCATION
	\item DATETIME
	\item NUMBER
	\item COLOR
	\item FREE\_TEXT
\end{itemize}
\section{Formalismo}
Per la comunicazione della struttura precedentemente definita tra l'agente intelligente e l'interfaccia vocale si è scelto di utilizzare il formato JSON

\subsection{Universe}
\begin{table}[H]
\centering
\caption{Struttura JSON Universe}
\label{Struttura JSON Universe}
\begin{tabular}{@{}|l|l|l|@{}}
\toprule
Nome    & Descrizione                                & Tipo                \\ \midrule
id      & Identificativo univoco                     & String             \\ \midrule
domains & Lista dei domini che compongono l'universo & JSONArray di Domain \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Domain}
\begin{table}[H]
\centering
\caption{Struttura JSON Domain}
\label{Struttura JSON Domain}
\begin{tabular}{@{}|l|l|l|@{}}
\toprule
Nome          & Descrizione                                                                   & Tipo                   \\ \midrule
id            & Identificativo univoco                                                        & String                 \\ \midrule
words         & Parole associate al dominio (es. light,lamp)                         & JSONArray di String    \\ \midrule
friendlyNames & Nomi associate al dominio (es. "palla" -> lampada) & JSONArray di String    \\ \midrule
operations    & Operazioni che possono essere eseguite nel dominio                   & JSONArray di Operation \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Operation}
\begin{table}[H]
\centering
\caption{Struttura JSON Operation}
\label{Struttura JSON Operation}
\begin{tabular}{@{}|l|l|l|@{}}
\toprule
Nome                & Descrizione                                                               & Tipo                   \\ \midrule
id                  & Identificativo univoco                                                    & String                 \\ \midrule
words               & Parole associate al dominio (es. light,lamp)                     & JSONArray di String    \\ \midrule
textInvocation      & Frasi per invocare l'operazione         & JSONArray di String    \\ \midrule
mandatoryParameters & Parametri obbligatori per l'operazione     & JSONArray di Parameter \\ \midrule
optionalParameters  & Parametri opzionali, non necessari & JSONArray di Parameter \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Parameter}
\begin{table}[H]
\centering
\caption{Struttura JSON Parameter}
\label{Struttura JSON Parameter}
\begin{tabular}{@{}|l|l|l|@{}}
\toprule
Nome & Descrizione            & Tipo          \\ \midrule
id   & Identificativo univoco & String        \\ \midrule
type & Tipo del parametro     & ParameterType \\ \bottomrule
\end{tabular}
\end{table}
\section{Modalità di comunicazione}
Per trasmettere l'informazione precedentemente descritta abbiamo scelto di utilizzare un canale di comunicazione WEB, seguendo l'architettura REST.\cite{rest}

Il sistema permette quindi di reperire l'informazione attraverso una chiamata GET all'indirizzo \textit{"/cose"}; la risposta consiste nel JSON precedentemente descritto, un esempio è presente in appendice a questa documentazione.
\chapter{Comunicazione voice - engine }
Il software di gestione vocale si occupa di estrarre i comandi che l'utente ha richiesto al sistema. Dopo aver completato il processamento dell'informazione restituisce la serializzazione in formato JSON di un oggetto di tipo Command.
\section{Command}
L'oggetto restituito rappresenta il comando che deve essere eseguito dal sistema, include inoltre la frase che l'utente ha pronunciato e la frase che nel sistema è associata al comando riconosciuto.
\subsection{Struttura JSON Command}
\begin{table}[H]
\centering
\caption{Struttura JSON Command}
\label{Struttura JSON Command}
\begin{tabular}{|l|l|l|}
\hline
Nome            & Descrizione                            & Tipo                        \\ \hline
domain          & Id del dominio                         & String                      \\ \hline
operation       & Id dell'operazione                     & String                      \\ \hline
said            & Frase ascoltata                        & String                      \\ \hline
understood      & Frase associata al comando nel sistema & String                      \\ \hline
paramValuePairs & Lista di parametri e relativi valori   & JSONArray di ParamValuePair \\ \hline
\end{tabular}
\end{table}
\subsection{Struttura JSON ParamValuePair}
\begin{table}[H]
\centering
\caption{Struttura JSON ParamValuePair}
\label{Struttura JSON ParamValuePair}
\begin{tabular}{|l|l|l|}
\hline
Nome  & Descrizione                  & Tipo      \\ \hline
id    & Id del parametro             & String    \\ \hline
type  & Tipologia del parametro      & ParamType \\ \hline
value & Valore assunto dal parametro & String    \\ \hline
\end{tabular}
\end{table}
\section{Modalità di comunicazione}
Per la trasmissione dei comandi abbiamo scelto di utilizzare l'architettura REST.
Il sistema è predisposto per l'esecuzione di comandi provenienti dall'esterno, offre un interfaccia all'indirizzo  \textit{"/sendCommand"}, attraverso il metodo POST.
Al seguente indirizzo è possibile inviare comandi nel formato precedentemente descritto.
\subsection{Risposta-feedback?}
Reminder
\chapter{Speech to text}
\chapter{Scelta della tecnologia}
\section{Linguaggio}
python (spicy.io ) vs Java (deeplearning4j + stanford nlp)
\chapter{Ricerca dell'operazione}
Dopo aver trasformato quanto detto dall'utente in testo, il sistema prova a mappare la frase su una delle azioni che che il sistema è in grado di eseguire.
In particolare viene cercato un dominio di esecuzione dell'operazione (es. Meteo, Luci) e l'operazione che si vuole compiere in questo dominio (es. Ricerca condizioni metereologiche, accensione della luce).


L'obbiettivo di questo sistema è di rendere generica l'interazione vocale, si è quindi dovuta trovare una metodologia che identificasse dominio e operazione indipendentemente dalle singole parole utilizzate, cercando quindi di astrarre il significato dai vocaboli.

 Il sistema per poter determinare l'operazione dispone di una lista di parole associate all'operazione, una lista di parole associate al dominio e opzionalmente una lista di frasi per l'invocazione dell'operazione in un dominio specifico.

\section{Database lessicale : wordNet}
Il primo approccio si è basato sull'utilizzo di wordNet, un database lessicale della lingua inglese.
In wordNet ad ogni lemma è associata una definizione, come in un normale dizionario, ma i lemmi sono anche collegati da una serie di relazioni, formando un grafo. In particolare le relazioni utilizzate nel progetto sono antonimia, iperonimia, sinonimia, metonimia.\cite{wordNet}

Utilizzato questo strumento è possibile reperire i sinonimi di una parola, dividendoli per categorie grammaticali (es. sinonimi di light come aggettivo o come nome).
Attraverso il confronto delle definizioni e delle relazioni è poi possibile determinare la similarità tra due vocaboli. Per definire tale metrica è possibile utilizzare molti diverse metodologie, tra i quali si è scelto di utilizzare quello definito come \textit{path}. \cite{wordNetWordSimilarity}

Questo approccio conta il numero di nodi che compongono il percorso più breve tra i due vocaboli, restituisce poi un coefficiente di similarità che corrisponde all'inverso della distanza precedentemente calcolata. Due vocaboli il cui significato è molto simile avranno delle strette relazioni con parole simili, quindi un alto coefficiente di similarità.\cite{wordNetPathSimilarity}
\subsection{Calcolo della similarità}
La similarità di un dominio con una frase viene calcolata come il massimo della similarità tra tutte le parole associate al dominio con tutte le parole presenti nella frase.

Lo stesso procedimento viene applicato alle operazioni e la similarità della coppia dominio/operazione è costituita dalla media aritmetica delle due similarità.
\subsection{Vantaggi}
Vantaggi:
 \begin{itemize}
  \item \textbf{Richiede poche risorse}: il database pesa meno di 100Mb.
  \item \textbf{Supporto ai phrasal verbs}: sono già compresi nel database come un singolo verbo (es. turn\_off).
\end{itemize}
\subsection{Svantaggi}
\begin{itemize}
  \item \textbf{Dizionario statico}: è stato creato manualmente e non viene aggiornato da anni.  
  \item \textbf{Indipendente dalla frase}: il risultato dell'analisi di similarità è indipendente dall'ordine delle parole.
  \item \textbf{Dipendente dal pos}: per cercare i sinonimi solo nella corretta categoria grammaticale è necessario affidarsi al Part Of Speech tagger, la cui affidabilità non è totale.
\end{itemize}
\newpage
\section{Part-Of-Speech tagging}
L'approccio precedentemente descritto presenta lo svantaggio di non tenere conto dell'ordine delle parole nella frase; si è quindi pensato di aggiungere un componente che tenga in considerazione questa informazione.

Il Part Of Speech tagger è un componente che si occupa di assegnare a ogni parola un tag, si occupa inoltre di definire le relazioni che intercorrono tra questi tag.\cite{pos}\cite{posCategories}
\subsection{Calcolo della similarità}
La prima fase consiste nella ricerca di un nome che corrisponde al dominio, da essa vengono poi seguite delle relazioni che legano il verbo a colui che compie l'azione o colui che la subisce. Nei verbi viene quindi cercata l'azione con l'approccio di path similarity attraverso wordnet.
\subsection{Vantaggi}
\begin{itemize}
  \item \textbf{Dipendente dalla frase}: grazie alle relazioni tra le parole viene realmente tenuto conto del senso della frase, migliorando quindi l'affidabilità del sistema.
\end{itemize}
\subsection{Svantaggi}
\begin{itemize}
  \item \textbf{Eccessivamente dipendente dal POS}: l'analisi si basa completamente sui risultati del POS, sia per le relazioni che per i TAG, nel caso di errori di questo componente (il cui risultati non è sempre affidabile) l'intera analisi è corrotta.
\end{itemize}
I vari componenti POS (spaCy, ClearNLP, CoreNLP, MATE, Turbo, SyntaxNet) hanno un affidabilità intorno al 93\%\cite{POS_scores}, questo tipo di analisi è estremamente difficoltosa nel caso di frasi la cui sintassi non è perfettamente corretta o eccessivamente gergale.  

Lo scopo del progetto è di rendere il più possibile flessibile il sistema, questo approccio avrebbe aumentato l'affidabilità, al prezzo di rendere il sistema funzionante solo per frasi con una sintassi perfetta. Abbiamo quindi scelto di togliere questo componente dal sistema.
\newpage
\section{Doc2vec}
Gli approcci decritti fino ad ora si basano sulla linguistica, nel campo dell'NLP negli ultimi anni sono stati compiuti dei passi avanti nel campo del machine learning. Approcci in questo campo hanno raggiunto performance comparabili, se non migliori, del precedente stato dell'arte. 

La maggior parte degli algoritmi di machine learning richiedono la trasformazione del testo in un vettore di dimensione fissa; generalmente l'approccio utilizzato è chiamato bag-of-words , esso però non tiene in considerazione l'ordine delle parole e la loro semantica.\cite{bow}

Doc2vec è un algoritmo che, come bag of words, permette di  rappresentare una parola, una frase, un paragrafo o un intero documento in un vettore di dimensione fissa. Risultati empirici hanno dimostrato che i vettori catturati attraverso doc2vec sono significativi e riescono a condensare l'informazione di un testo di lunghezza variabile.\cite{doc2vec}
\subsection{Creazione del modello}
L'algoritmo precedentemente descritto per il suo funzionamento necessità di dati precedentemente classificati, se sul disco non è presente nessun modello ne viene creato uno che associa le frasi associate alle operazioni (campo textInvocation del JSON di input) all'operazione stessa. 

Se è già presente un modello queste frasi vengono aggiunte a quelle presenti. Dopo aver completato il modello viene avviata la fase di training dei vettori.
\subsection{Feedback}
Il sistema necessità di una grande mole di dati per l'allenamento dei vettori, si è quindi introdotto nel sistema di interazione vocale un metodo di feedback. Dopo l'esecuzione di un comando si ha la possibilità di notificare l'agente se il comando eseguito non è quanto si era richiesto, in caso contrario viene assunto che il comando sia corretto. L'insieme delle frasi corrette viene quindi utilizzato successivamente per l'istruzione dei vettori.
\subsection{Calcolo della similarità}
Dopo aver istruito il modello e aver creato i vettori per ogni frase viene calcolato il vettore medio di tutte le frasi che rappresentano la stessa operazione. Quando l'utente pronuncia una frase viene calcolato l'angolo tra il vettore calcolato per la frase stessa e tutti i vettori medi precedentemente calcolati. Viene poi restituita all'utente la categoria associata al vettore più vicino
\begin{center}
\begin{math}
 \textit{similarity(A,B)} = \cos(\theta) = {A \cdot B \over \|A\| \|B\|}.
 \end{math}
 \end{center}
\subsection{Vantaggi}
\begin{itemize}
  \item \textbf{Dizionario dinamico}: il modello viene creato automaticamente e viene migliorato con il tempo.
  \item \textbf{Dipende dalla frase}: l'algoritmo considera l'ordine delle parole, cattura quindi la semantica della frase.
  \item \textbf{Miglioramento continuo}: il sistema è in grado di apprendere, migliora quindi con il tempo.
  \item \textbf{Indipendente dalle parole}: l'algoritmo apprende, quindi riesce ad imparare nuove parole.
\end{itemize}
\subsection{Svantaggi}
\begin{itemize}
  \item \textbf{Grande mole di dati}: Per avere una classificazione accurata è necessario avere un grande numero di frasi associate a ogni operazione e ad ogni dominio
  \item \textbf{Piccole variazioni}: L'algoritmo fatica a percepire piccole variazioni che però modificano totalmente il senso della frase (turn on vs. turn off)
\end{itemize}
\subsection{Sviluppi futuri}
Si è empiricamente dimostrato che in una fase iniziale è difficile creare un modello sufficiente ad istruire il sistema. Non è quindi realizzabile un sistema che si basi solo su questo approccio nei tempi del progetto di bachelor. Si è comunque scelto di realizzare l'intera infrastruttura, cosi che con il passare del tempo il modella possa migliorare fino ad essere in grado di sostituire o almeno collaboratore con l'infrastruttura attuale.
\newpage
%	Word2vec
\section{Word2vec}
I modelli precedentemente possono essere racchiusi in due categorie:
\begin{itemize}
  \item \textbf{Statici}: wordnet, pos. Sono basati su un dizionario, non migliorano con il tempo.
  \item \textbf{Dinamici}: doc2vec, skip-thoughts vector. Sono basati su tecniche di deep learning, migliorano con il tempo, ma necessitano di un modello di allenamento.
\end{itemize}
Si è quindi cercato di trovare un approccio che riuscisse a eliminare la staticità derivante dall'utilizzo di un dizionario, senza però dover creare un modello di allenamento di una rete neurale.
Per fare ciò si è ideato sistema basato sull'algoritmo word2vec, il quale, attraverso una rete neurale a due livelli, prende come input del testo e restituisce una serie di vettori. 

Questo algoritmo è molto rapido nella sua fase di apprendimento, per questo motivo è possibile allenarlo su una grande base di dati (es. l'intero wikipedia), cosi che i vettori ottenuti siano generici.\cite{word2vec}
\subsection{Calcolo della similarità}
Per poter associate una frase pronunciata dall'utente ad un dominio e un operazione viene sfruttata, come in doc2vec, la similarità del coseno. In particolare vengono confrontati i vettori rappresentati le parole associate al dominio (words del JSON) con tutte le parole nella frase, dopo di che viene ritornata la maggior similarità trovata. 

Lo stesso procedimento viene applicato alla ricerca dell'operazione. 

La similarità finale è calcolata come la media aritmetica della similarità del dominio con quella dell'operazione.
\subsection{Approccio ad albero}
Grazie a word2vec la similarità tra due parole viene ridotta a un prodotto scalare tra due vettori, il che è eseguito molto rapidamente. Il sistema calcola quindi il valore si similarità di tutti i domini, poi calcola la similarità di tutte le operazioni associate a tutti i domini e non solo il migliore. Viene poi scelta l'operazione che possiede la similarità del dominio associato + similarità dell'operazione stessa maggiore.
\subsection{Vantaggi}
\begin{itemize}
  \item \textbf{Dizionario dinamico}: il modello viene creato automaticamente, può essere addestrato su qualunque base di dati.
  \item \textbf{Efficiente}: l'intero calcolo della similarità è ricondotto a prodotti scalari.
    \item \textbf{Indipendente dalle parole}: l'algoritmo apprende, quindi riesce ad imparare nuove parole.
\end{itemize}
\subsection{Svantaggi}
\begin{itemize}
  \item \textbf{Scelta del modello}: le prestazioni e le risorse utilizzate dipendono dalla scelta del modello. Maggiori informazioni nel capitolo dedicato.
  \item \textbf{Parole composte}: con le classiche tecniche di allenamento i vettori vengono create per singole parole, non sono quindi supportati dal sistema i phrasal verbs.
\end{itemize}
\subsection{Parole composte}
Nel caso a un'operazione o a un dominio si voglia associate una parola composta, ad esempio "turn off", essa deve essere aggiunta al vettore delle parole associate seguendo la convenzione dei nomi "Lower Camel Case". Il calcolo della similarità verrà poi effettuato come la media della similarità dei token che compongono la parola.\cite{lcc}
\subsection{Phrasal verbs}
Come evidenziato negli svantaggi il sistema non sarebbe in grado di analizzare la similarità una una parola composta, ad esempio "turn on", e una parola singola che possiede lo stesso significato, ad esempio "activate".
Per questo motivo, in fase di caricamento del sistema, quando vengono analizzate le parole associate a ogni operazione o dominio, un modulo dedicato si occupa di aggiungere automaticamente sinonimi della parola.

Nella maggior parte dei casi nei sinonimi è contenuto un verbo della categoria opposta (un phrasal verb per un verbo composto da una parola singola e l'inverso).
Il problema potrebbe essere risolto con un modello word2vec che contiene phrasal verbs e parole composte.
% Modelli
\chapter{Modelli word2vec}
Il sistema descritto nella sezione precedente basa il calcolo della similarità sui vettori estratti dal modello. Essi sono direttamente correlati al corpus \cite{corpus} utilizzato per l'istruzione della rete neurale. Nel web sono presenti modelli già allenati su basi di dati di grandi dimensioni \cite{trained_models}.

Data la dimensione di del corpus sono presenti un insieme di parole che è molto superiore a quelle che possono essere utilizzate all'interno di un ambiente di automazione casalinga. Sempre grazie alla mole di dati però questi vettori rappresentano pienamente il senso di una parola, al punto di essere utilizzabili in numerosi contesti.
\section{Google word2vec}
Nella prima implementazione del sistema si è scelto di utilizzare il modello fornito insieme all'implementazione di google, il quale è stato addestrato sull'intero google news. I suoi vettori possiedono 300 dimensioni e rappresentano 3 milioni di parole. Questo modello è molto generico, ma le sue dimensioni sono elevate, infatti il sistema necessità di circa 8GB di memoria RAM per il suo funzionamento.
\section{Allenamento di un Modello}
Per migliorare le performance del sistema si potrebbe sostituire il modello fornito da google con un modello addestrato su parole e frasi che realmente possono essere di interesse all'interno di un ambiente domestico. Per questo motivo il lo stesso sistema di logging delle frasi utilizzato da doc2vec viene utilizzato per istruire un modello proprietario. Nei tempi del progetto di bachelor si ritiene che non sia possibile raggiungere la massa di informazioni necessaria a creare dei vettori che riescano a catturare il significato delle parole. Esso potrebbe essere uno sviluppo futuro del sistema, dopo qualche mese di utilizzo quotidiano. L'implementazione realizzata contiene le funzioni necessarie all'istruzione di un modello ed è predisposta a sostituire il modello attuale.
\section{sense2vec}
I modelli allenati con word2vec associano a ogni parola un vettore, anche quando questa parola assume più significati, il vettore tende poi verso il significato più comune. Per ovviate questo problema è nato sense2vec, il quale associa a ogni parola più vettori, uno per ogni significato. É possibile ad esempio creare il vettore corrispondente a una parola associata al suo Part Of Speech Tag.  \cite{posCategories} \cite{sense2vec} 

Con lo stesso approccio è anche possibile unire in un vettore più parole, ad esempio i phrasal verbs, cosi da poter mappare un senso e non una sola parola in un vettore. Si è quindi pensato che, una volta raggiunta la necessaria quantità di informazioni, si potrebbe creare un modello seguendo questo approccio, cosi da eliminare il dizionario wordnet dal sistema.


\chapter{Ricerca dei parametri}
\subsection{openie}

\chapter{Lattex Tutorial}
%	Introduzione sotto l'inizio del capitolo
\lipsum[13]

%	Unordered listMa 
\begin{itemize}
  \item Elemento A
  \item Elemento B
  \item Elemento C
\end{itemize}

 % 	Unordered list con pallino diverso
\begin{itemize}
  \item[-] Elemento A
  \item[-] Elemento B
  \item[-] Elemento C
\end{itemize}

%	Ordered list
\begin{enumerate}
 \item Alpha
  \item Beta
  \item Gamma
\end{enumerate}

% 	FootNote
\footnote{Questa è una nota a pi\'e di pagina.}

% 	Bold, Italiic, Underlined
\texttt{Questo testo ha una spaziatura fissa}

\textit{Questo testo \`e in italico}

\textbf{Questo testo \`e in grassetto}

\textsc{Questo testo \`e in maiuscoletto}

\underline{Questo testo \`e sottolineato} \\

Citazione:
\begin{quote}
\lipsum[23]
\end{quote}

\section{Sezione}

\lipsum[23]

\subsection{Sotto sezione}

Un po' di matematica: \newline

\begin{math}
\frac{n!}{k!(n-k)!} = {n \choose k}
\end{math} \newline

Un po' di matematica centrata:

\begin{center}
\begin{math}
\frac{n!}{k!(n-k)!} = {n \choose k}
\end{math}
\end{center}

Oppure con \$\$

$$
\frac{n!}{k!(n-k)!} = {n \choose k}
$$

Oppure anche direttamente nel testo ${1}\over{n}$ \\

\lipsum[23]

\bibliographystyle{unsrt}
\bibliography{bibliografia}
\end{document}
